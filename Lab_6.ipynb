{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqGbuXrOHBoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07199f8d-2e96-4a69-e043-44f11762f1b8"
      },
      "source": [
        "4+ 7"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51l3W2iQRTKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a710ca-6119-4db8-ee8f-d7b352caa3a5"
      },
      "source": [
        "%%writefile matrixMultiplication.cu\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <assert.h>\n",
        "#include <curand.h>\n",
        "#include <curand_kernel.h>\n",
        "#define N 4000\n",
        "\n",
        "inline cudaError_t checkCuda(cudaError_t result)\n",
        "{\n",
        "  if (result != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime Error: %s\\n\", cudaGetErrorString(result));\n",
        "    assert(result == cudaSuccess);\n",
        "  }\n",
        "  return result;\n",
        "}\n",
        "\n",
        "// CUDA kernel to multiply matrices\n",
        "__global__ void mult(float **x, float **y, float **z){\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int stride = blockDim.x * gridDim.x;\n",
        "    // stride not memory coalescent; might need to fix\n",
        "    for (int i = index; i < N; i += stride) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            float sum = 0;\n",
        "            for (int k = 0; k < N; k++) {\n",
        "                sum += x[i][k] * y[k][j];\n",
        "            }\n",
        "            z[i][j] = sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// CUDA kernel to init the matrices\n",
        "// NOT USED SINCE RAND() DOESN'T WORK IN KERNEL FUNCTIONS\n",
        "//__global__ void mult(float **x, float **y){\n",
        "//    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "//    int stride = blockDim.x * gridDim.x;\n",
        "//    // stride not memory coalescent; might need to fix\n",
        "//    for (int i = index; i < N; i += stride) {\n",
        "//        for (int j = 0; j < N; j++) {\n",
        "//            x[i][j] = (float) rand() / RAND_MAX;\n",
        "//            y[i][j] = (float) rand() / RAND_MAX;\n",
        "//        }\n",
        "//    }\n",
        "//}\n",
        "\n",
        "int main(void){\n",
        "    float **x, **y, **z;\n",
        "    // Allocate Unified Memory -- accessible from CPU or GPU\n",
        "    checkCuda(cudaMallocManaged(&x, N*sizeof(float *)));\n",
        "    checkCuda(cudaMallocManaged(&y, N*sizeof(float *)));\n",
        "    checkCuda(cudaMallocManaged(&z, N*sizeof(float *)));\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        checkCuda(cudaMallocManaged(&y[i], N*sizeof(float)));\n",
        "        checkCuda(cudaMallocManaged(&x[i], N*sizeof(float)));\n",
        "        checkCuda(cudaMallocManaged(&z[i], N*sizeof(float)));\n",
        "        //printf(\"%d\\n\", i);\n",
        "    }\n",
        "\n",
        "    // initialize x and y arrays on the host\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            y[i][j] = (float) rand() / RAND_MAX;\n",
        "            x[i][j] = (float) rand() / RAND_MAX;\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    //for timing\n",
        "    float milliseconds=0.0;\n",
        "    cudaEvent_t start,stop;\n",
        "    checkCuda(cudaEventCreate(&start));\n",
        "    checkCuda(cudaEventCreate(&stop));\n",
        "\n",
        "\n",
        "    // Launch kernel on 1M elements on the GPU\n",
        "    int blockSize = 100;\n",
        "    int numBlocks = 256;\n",
        "    cudaEventRecord(start);\n",
        "    mult<<<numBlocks, blockSize>>>(x, y, z);\n",
        "\n",
        "    // Wait for GPU to finish before accessing on host\n",
        "    checkCuda(cudaEventRecord(stop));\n",
        "    checkCuda(cudaDeviceSynchronize());\n",
        "\n",
        "    checkCuda(cudaEventElapsedTime(&milliseconds, start, stop));\n",
        "    std::cout << \"Elapsed time for Cuda matrix multiplication: \" << milliseconds/1000 << std::endl;\n",
        "\n",
        "    // Free memory\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        checkCuda(cudaFree(x[i]));\n",
        "        checkCuda(cudaFree(y[i]));\n",
        "        checkCuda(cudaFree(z[i]));\n",
        "    }\n",
        "    checkCuda(cudaFree(x));\n",
        "    checkCuda(cudaFree(y));\n",
        "    checkCuda(cudaFree(z));\n",
        "\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting matrixMultiplication.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCfL9fJ4TALE"
      },
      "source": [
        "!nvcc  -o matrixMultiplication matrixMultiplication.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1TEMtQ7TIeK",
        "outputId": "173d6be7-62af-4263-834f-5b4ce6710331"
      },
      "source": [
        "!./matrixMultiplication"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapsed time for Cuda matrix multiplication: 4.46919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z6wCtGn80Gk",
        "outputId": "233d1071-bb5a-4afa-b7ea-a5bc5f37a165"
      },
      "source": [
        "%%writefile c_implementation.c\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <sys/time.h>\n",
        "#include <pthread.h>\n",
        "#include <stdint.h>\n",
        "#include <time.h>\n",
        "#include <omp.h>\n",
        "\n",
        "// #define _POSIX_C_SOURCE >= 199309L\n",
        "#define CORE 4\n",
        "#define HEIGHT1 4000\n",
        "#define WIDTH1 4000\n",
        "#define HEIGHT2 4000\n",
        "#define WIDTH2 4000\n",
        "\n",
        "float CMat[HEIGHT1][WIDTH1], DMat[HEIGHT2][WIDTH2], multPthread[HEIGHT1][WIDTH2], multSeq[HEIGHT1][WIDTH2], multOpenMP[HEIGHT1][WIDTH2];\n",
        "pthread_t thread[CORE];\n",
        "struct timespec begin, end;\n",
        "\n",
        "\n",
        "\n",
        "void *multMatrices_openmp()\n",
        "{\n",
        "    int row, col, k;\n",
        "\n",
        "    #pragma omp parallel num_threads(4) shared(multOpenMP, CMat, DMat) private(row, col, k)\n",
        "    {\n",
        "\n",
        "    #pragma omp for\n",
        "    for (row = 0; row < HEIGHT1; row++)\n",
        "    {\n",
        "        for (col = 0; col < WIDTH2; col++)\n",
        "        {\n",
        "            for (k = 0; k < WIDTH1; k++)\n",
        "            {\n",
        "                multOpenMP[row][col] += CMat[row][k] * DMat[k][col];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    }\n",
        "\n",
        "    return NULL;\n",
        "}\n",
        "\n",
        "void *multMatrices_pthread(void *arg)\n",
        "{\n",
        "    int row, col, k;\n",
        "    float val = 0;\n",
        "\n",
        "    int core = (intptr_t)arg;\n",
        "    // Each thread computes 1/core of matrix multiplication\n",
        "    for (row = core * HEIGHT1 / CORE; row < (core + 1) * HEIGHT1 / CORE; row++)\n",
        "    {\n",
        "        for (col = 0; col < WIDTH2; col++)\n",
        "        {\n",
        "            val = 0;\n",
        "            for (k = 0; k < WIDTH1; k++)\n",
        "            {\n",
        "\n",
        "                val += CMat[row][k] * DMat[k][col];\n",
        "            }\n",
        "\n",
        "            multPthread[row][col] = val;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return NULL;\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[])\n",
        "{\n",
        "    int i, j;\n",
        "    int err_val;\n",
        "    int num_errors = 0;\n",
        "    double timeSeq, timePthread, timeOpenMP;\n",
        "\n",
        "    int row, col, k;\n",
        "    float val = 0;\n",
        "\n",
        "    for (i = 0; i < HEIGHT1; i++)\n",
        "    {\n",
        "        for (j = 0; j < WIDTH1; j++)\n",
        "        {\n",
        "            CMat[i][j] = (float)rand() / RAND_MAX;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for (i = 0; i < HEIGHT2; i++)\n",
        "    {\n",
        "        for (j = 0; j < WIDTH2; j++)\n",
        "        {\n",
        "            DMat[i][j] = (float)rand() / RAND_MAX;\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    err_val = clock_gettime(CLOCK_MONOTONIC, &begin);\n",
        "    if (err_val != 0) {\n",
        "        fprintf(stderr, \"timing failure in %s at line %d\\n\", __FILE__, __LINE__);\n",
        "        perror(NULL);\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    // calculate sequential product\n",
        "    for (row = 0; row < HEIGHT1; row++)\n",
        "    {\n",
        "        for (col = 0; col < WIDTH2; col++)\n",
        "        {\n",
        "            val = 0;\n",
        "            for (k = 0; k < WIDTH1; k++)\n",
        "            {\n",
        "                val += CMat[row][k] * DMat[k][col];\n",
        "            }\n",
        "\n",
        "            multSeq[row][col] = val;\n",
        "        }\n",
        "    }\n",
        "    err_val = clock_gettime(CLOCK_MONOTONIC, &end);\n",
        "    if (err_val != 0) {\n",
        "        fprintf(stderr, \"timing failure in %s at line %d\\n\", __FILE__, __LINE__);\n",
        "        perror(NULL);\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    timeSeq = end.tv_sec - begin.tv_sec;\n",
        "    timeSeq += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n",
        "\n",
        "    printf(\"Time sequential: %f\\n\", timeSeq);\n",
        "\n",
        "\n",
        "\n",
        "    // pthread implementation\n",
        "    err_val = clock_gettime(CLOCK_MONOTONIC, &begin);\n",
        "    if (err_val != 0) {\n",
        "        fprintf(stderr, \"timing failure in %s at line %d\\n\", __FILE__, __LINE__);\n",
        "        perror(NULL);\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    for (i = 0; i < CORE; i++)\n",
        "    {\n",
        "        err_val = pthread_create(&thread[i], NULL, &multMatrices_pthread, (void *)(intptr_t)i);\n",
        "        if (err_val != 0)\n",
        "        {\n",
        "            fprintf(stderr, \"pthread create failure in %s at line %d\\n\", __FILE__, __LINE__);\n",
        "            perror(NULL);\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for (i = 0; i < CORE; i++)\n",
        "    {\n",
        "        err_val = pthread_join(thread[i], NULL);\n",
        "        if (err_val != 0)\n",
        "        {\n",
        "            fprintf(stderr, \"pthread join failure in %s at line %d\\n\", __FILE__, __LINE__);\n",
        "            perror(NULL);\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "    }\n",
        "    err_val = clock_gettime(CLOCK_MONOTONIC, &end);\n",
        "    if (err_val != 0) {\n",
        "        fprintf(stderr, \"timing failure in %s at line %d\\n\", __FILE__, __LINE__);\n",
        "        perror(NULL);\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    timePthread = end.tv_sec - begin.tv_sec;\n",
        "    timePthread += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n",
        "\n",
        "    for (i = 0; i < HEIGHT1; i++) {\n",
        "        for (j = 0; j < WIDTH2; j++) {\n",
        "            if (multSeq[i][j] != multPthread[i][j]) {\n",
        "                num_errors++;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    if (num_errors != 0)\n",
        "    {\n",
        "        printf(\"Multiplication pthread: Failure\\n\");\n",
        "        printf(\"Num errors: %d\\n\", num_errors);\n",
        "        return 1;\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        printf(\"Multiplication pthread: Success!!!\\n\");\n",
        "        printf(\"Time pthread: %f\\n\", timePthread);\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    // openMP implementation 1\n",
        "    num_errors = 0;\n",
        "    err_val = clock_gettime(CLOCK_MONOTONIC, &begin);\n",
        "    if (err_val != 0) {\n",
        "        fprintf(stderr, \"timing failure in %s at line %d\\n\", __FILE__, __LINE__);\n",
        "        perror(NULL);\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    multMatrices_openmp();\n",
        "\n",
        "    err_val = clock_gettime(CLOCK_MONOTONIC, &end);\n",
        "    if (err_val != 0) {\n",
        "        fprintf(stderr, \"timing failure in %s at line %d\\n\", __FILE__, __LINE__);\n",
        "        perror(NULL);\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    \n",
        "    timeOpenMP = end.tv_sec - begin.tv_sec;\n",
        "    timeOpenMP += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n",
        "\n",
        "    for (i = 0; i < HEIGHT1; i++) {\n",
        "        for (j = 0; j < WIDTH2; j++) {\n",
        "            if (multSeq[i][j] != multOpenMP[i][j]) {\n",
        "                num_errors++;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (num_errors != 0)\n",
        "    {\n",
        "        printf(\"Multiplication OpenMP 1: Failure\\n\");\n",
        "        printf(\"Num errors: %d\\n\", num_errors);\n",
        "        return 1;\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        printf(\"Multiplication OpenMP 1: Success!!!\\n\");\n",
        "        printf(\"Time OpenMP: %f\\n\", timeOpenMP);\n",
        "    }\n",
        "    \n",
        "    return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing c_implementation.c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZg_BsfI9LZS"
      },
      "source": [
        "!gcc c_implementation.c -O3 -lpthread -fopenmp -o c_implementation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFxhBOWG9x77",
        "outputId": "cc2712a7-1540-491b-9a23-9e1b935004e8"
      },
      "source": [
        "!./c_implementation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time sequential: 132.980816\n",
            "Multiplication pthread: Success!!!\n",
            "Time pthread: 123.727424\n",
            "Multiplication OpenMP 1: Success!!!\n",
            "Time OpenMP: 123.704862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MLKbo4mGYvr",
        "outputId": "24488550-a493-44a6-9fca-1cfa98578ad6"
      },
      "source": [
        "%%writefile matrixMultiplicationtest.cu\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <assert.h>\n",
        "#include <curand.h>\n",
        "#include <curand_kernel.h>\n",
        "# define N 100\n",
        "\n",
        "inline cudaError_t checkCuda(cudaError_t result)\n",
        "{\n",
        "  if (result != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime Error: %s\\n\", cudaGetErrorString(result));\n",
        "    assert(result == cudaSuccess);\n",
        "  }\n",
        "  return result;\n",
        "}\n",
        "\n",
        "// CUDA kernel to multiply matrices\n",
        "__global__ void mult(float **x, float **y, float **z){\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int stride = blockDim.x * gridDim.x;\n",
        "    // stride not memory coalescent; might need to fix\n",
        "    for (int i = index; i < N; i += stride) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            float sum = 0;\n",
        "            for (int k = 0; k < N; k++) {\n",
        "                sum += x[i][k] * y[k][j];\n",
        "            }\n",
        "            z[i][j] = sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// CUDA kernel to init the matrices\n",
        "//__global__ void mult(float **x, float **y){\n",
        "//    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "//    int stride = blockDim.x * gridDim.x;\n",
        "//    // stride not memory coalescent; might need to fix\n",
        "//    for (int i = index; i < N; i += stride) {\n",
        "//        for (int j = 0; j < N; j++) {\n",
        "//            x[i][j] = (float) rand() / RAND_MAX;\n",
        "//            y[i][j] = (float) rand() / RAND_MAX;\n",
        "//        }\n",
        "//    }\n",
        "//}\n",
        "\n",
        "// check that our cuda multiplication algorithm is correct\n",
        "int main(void){\n",
        "    float **x, **y, **z, **multSeq;\n",
        "    int row, col, k, num_errors;\n",
        "    float val;\n",
        "\n",
        "    // Allocate Unified Memory -- accessible from CPU or GPU\n",
        "    checkCuda(cudaMallocManaged(&x, N*sizeof(float *)));\n",
        "    checkCuda(cudaMallocManaged(&y, N*sizeof(float *)));\n",
        "    checkCuda(cudaMallocManaged(&z, N*sizeof(float *)));\n",
        "    checkCuda(cudaMallocManaged(&multSeq, N*sizeof(float *)));\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        checkCuda(cudaMallocManaged(&y[i], N*sizeof(float)));\n",
        "        checkCuda(cudaMallocManaged(&x[i], N*sizeof(float)));\n",
        "        checkCuda(cudaMallocManaged(&z[i], N*sizeof(float)));\n",
        "        checkCuda(cudaMallocManaged(&multSeq[i], N*sizeof(float)));\n",
        "    }\n",
        "\n",
        "    // initialize matrices on GPU because faster (less data movement from CPU to GPU if data exists on GPU)\n",
        "    // initialize x and y arrays on the host\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            y[i][j] = (float) rand() / RAND_MAX;\n",
        "            x[i][j] = (float) rand() / RAND_MAX;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for (row = 0; row < N; row++)\n",
        "    {\n",
        "        for (col = 0; col < N; col++)\n",
        "        {\n",
        "            val = 0;\n",
        "            for (k = 0; k < N; k++)\n",
        "            {\n",
        "                val += x[row][k] * y[k][col];\n",
        "            }\n",
        "\n",
        "            multSeq[row][col] = val;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    //for timing\n",
        "    float milliseconds=0.0;\n",
        "    cudaEvent_t start,stop;\n",
        "    checkCuda(cudaEventCreate(&start));\n",
        "    checkCuda(cudaEventCreate(&stop));\n",
        "\n",
        "    // Launch kernel on 1M elements on the GPU\n",
        "    int blockSize = 100;\n",
        "    int numBlocks = 100;\n",
        "    checkCuda(cudaEventRecord(start));\n",
        "    mult<<<numBlocks, blockSize>>>(x, y, z);\n",
        "\n",
        "    // Wait for GPU to finish before accessing on host\n",
        "    checkCuda(cudaEventRecord(stop));\n",
        "    checkCuda(cudaDeviceSynchronize());\n",
        "\n",
        "    checkCuda(cudaEventElapsedTime(&milliseconds, start, stop));\n",
        "    std::cout << \"Cuda elapsed time: \" << milliseconds/1000 << std::endl;\n",
        "\n",
        "    num_errors = 0;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            // handling float precision\n",
        "            if (abs(multSeq[i][j] - z[i][j]) > 0.001) {\n",
        "                num_errors++;\n",
        "                printf(\"value 1 = %f value 2 = %f\\n\", multSeq[i][j], z[i][j]);\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (num_errors != 0)\n",
        "    {\n",
        "        printf(\"Multiplication Cuda: Failure\\n\");\n",
        "        printf(\"Num errors: %d\\n\", num_errors);\n",
        "        //return 1;\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        printf(\"Multiplication Cuda: Success!!!\\n\");\n",
        "        //printf(\"Time OpenMP: %f\\n\", timeOpenMP);\n",
        "    }\n",
        "    \n",
        "    // Free memory\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        checkCuda(cudaFree(x[i]));\n",
        "        checkCuda(cudaFree(y[i]));\n",
        "        checkCuda(cudaFree(z[i]));\n",
        "        checkCuda(cudaFree(multSeq[i]));\n",
        "    }\n",
        "    checkCuda(cudaFree(x));\n",
        "    checkCuda(cudaFree(y));\n",
        "    checkCuda(cudaFree(z));\n",
        "    checkCuda(cudaFree(multSeq));\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting matrixMultiplicationtest.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSpnQniAH4TD"
      },
      "source": [
        "!nvcc  -o matrixMultiplicationtest matrixMultiplicationtest.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cln-e-4PH9YJ",
        "outputId": "e850d946-0913-4666-93f1-2d8325ee7d18"
      },
      "source": [
        "!./matrixMultiplicationtest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda elapsed time: 0.00263782\n",
            "Multiplication Cuda: Success!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLlA48dXPry9"
      },
      "source": [
        "# Timings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RMyOr0-PuLZ"
      },
      "source": [
        "### Pthread, sequential and openMP timings taken on 127x20, CUDA timings taken on colab \n",
        "\n",
        "Timings for CUDA-\n",
        "\n",
        "* N = 4000 and <<<256, 100>>> - 4.3152\n",
        "* N = 4000 and <<<1024, 100>>> - 4.53956\n",
        "* N = 10000 and <<<256, 100>>> - 63.0042\n",
        "* N = 10000 and <<<1024, 100>>> - 64.1735\n",
        "\n",
        "\n",
        "Timings for 4 threads (N = 4000)-\n",
        "\n",
        "\n",
        "*   OpenMP -  74.498309\n",
        "*   Pthread - 74.690056\n",
        "*   Sequential - 305.769212\n",
        "\n",
        "Timings for 2 threads (N = 4000)-\n",
        "\n",
        "\n",
        "*   OpenMP -  158.567216\n",
        "*   Pthread - 163.935921\n",
        "*   Sequential - 304.99212"
      ]
    }
  ]
}